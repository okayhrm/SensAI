"""
AI COURSE GENERATION SCORING SYSTEM

1. QUALITY SCORE (0-100):
=======================

Base Score: 75 (default starting point)

Deductions:
- Review failed: -25 points (results in 50/100)
- Reading level mismatch: -10 points
- High duplicate content: -15 points
- Poor question quality: -10 points
- Vague learning objectives: -10 points
- Insufficient examples: -5 points

Bonuses:
- Excellent content structure: +10 points
- High-quality examples: +5 points
- Clear learning objectives: +5 points
- Good question diversity: +5 points

Why you got 50/100:
- Started at 75
- Review failed (-25) = 50
- The review failed because the AI couldn't properly assess the generated content

2. INCLUSIVITY SCORE (1-10):
============================

Base Score: 7 (default starting point)

Factors that increase score:
- Diverse examples from multiple cultures: +1
- Gender-neutral language and examples: +1
- Multiple socioeconomic perspectives: +1
- Accessible language and concepts: +0.5
- Global rather than Western-centric examples: +0.5

Factors that decrease score:
- Cultural bias detected: -2
- Gender stereotypes: -2  
- Socioeconomic assumptions: -1
- Exclusive language: -1
- Single cultural perspective: -1

Why you got 7/10:
- Default score with no major bias detected
- But also no exceptional inclusivity efforts identified

3. BIAS SEVERITY SCORE (1-10):
==============================

1-3: Minimal bias (minor issues, easily correctable)
- Example: Slight preference for Western examples

4-6: Moderate bias (needs attention)
- Example: Some gender stereotypes in examples

7-10: Severe bias (major revision needed, may block publishing)
- Example: Discriminatory content, harmful stereotypes

Why you got 1/10:
- Very low bias detected
- Content appears to be relatively neutral and appropriate

4. WHY REVIEW FAILED:
====================

Common reasons for review failure:
- AI service timeout or error
- Generated content format issues
- Network connectivity problems
- AI model overloaded
- Validation errors in the review process

The "manual review recommended" message appears when:
- The automated AI review couldn't complete
- There were technical errors during review
- Content couldn't be properly analyzed

This doesn't mean the content is bad - just that it needs human review.
"""

def calculate_quality_score(
    review_failed: bool = False,
    reading_level_issues: bool = False,
    duplicate_count: int = 0,
    question_quality: str = "good",  # good, fair, poor
    objective_clarity: str = "good",  # good, fair, poor
    example_count: int = 3,
    content_structure: str = "good"  # excellent, good, fair, poor
) -> tuple[int, list[str]]:
    """
    Calculate quality score with detailed breakdown.
    
    Returns:
        tuple: (score, explanation_list)
    """
    base_score = 75
    score = base_score
    explanations = [f"Starting score: {base_score}"]
    
    if review_failed:
        score -= 25
        explanations.append("Review failed: -25 points")
    
    if reading_level_issues:
        score -= 10
        explanations.append("Reading level issues: -10 points")
    
    if duplicate_count > 3:
        deduction = min(15, duplicate_count * 3)
        score -= deduction
        explanations.append(f"Duplicate content ({duplicate_count} items): -{deduction} points")
    
    if question_quality == "poor":
        score -= 10
        explanations.append("Poor question quality: -10 points")
    elif question_quality == "fair":
        score -= 5
        explanations.append("Fair question quality: -5 points")
    
    if objective_clarity == "poor":
        score -= 10
        explanations.append("Vague learning objectives: -10 points")
    elif objective_clarity == "fair":
        score -= 5
        explanations.append("Unclear learning objectives: -5 points")
    
    if example_count < 2:
        score -= 5
        explanations.append("Insufficient examples: -5 points")
    
    # Bonuses
    if content_structure == "excellent":
        score += 10
        explanations.append("Excellent content structure: +10 points")
    
    if question_quality == "excellent":
        score += 5
        explanations.append("High-quality questions: +5 points")
    
    if objective_clarity == "excellent":
        score += 5
        explanations.append("Clear learning objectives: +5 points")
    
    # Cap between 0-100
    score = max(0, min(100, score))
    explanations.append(f"Final score: {score}/100")
    
    return score, explanations

def calculate_inclusivity_score(
    diverse_examples: bool = False,
    gender_neutral: bool = True,
    multiple_perspectives: bool = False,
    accessible_language: bool = True,
    global_examples: bool = False,
    cultural_bias: bool = False,
    gender_stereotypes: bool = False,
    socioeconomic_assumptions: bool = False
) -> tuple[int, list[str]]:
    """
    Calculate inclusivity score with detailed breakdown.
    
    Returns:
        tuple: (score, explanation_list)
    """
    base_score = 7
    score = base_score
    explanations = [f"Starting inclusivity score: {base_score}"]
    
    # Positive factors
    if diverse_examples:
        score += 1
        explanations.append("Diverse cultural examples: +1 point")
    
    if gender_neutral:
        explanations.append("Gender-neutral language maintained: baseline")
    
    if multiple_perspectives:
        score += 1
        explanations.append("Multiple socioeconomic perspectives: +1 point")
    
    if accessible_language:
        explanations.append("Accessible language used: baseline")
    
    if global_examples:
        score += 0.5
        explanations.append("Global examples used: +0.5 points")
    
    # Negative factors
    if cultural_bias:
        score -= 2
        explanations.append("Cultural bias detected: -2 points")
    
    if gender_stereotypes:
        score -= 2
        explanations.append("Gender stereotypes found: -2 points")
    
    if socioeconomic_assumptions:
        score -= 1
        explanations.append("Socioeconomic assumptions: -1 point")
    
    # Cap between 1-10
    score = max(1, min(10, score))
    explanations.append(f"Final inclusivity score: {score}/10")
    
    return int(score), explanations

# Example usage:
if __name__ == "__main__":
    # Your case: Review failed
    quality_score, quality_explanation = calculate_quality_score(
        review_failed=True,
        reading_level_issues=False,
        duplicate_count=0,
        question_quality="unknown",  # Can't assess due to review failure
        objective_clarity="unknown",
        example_count=3
    )
    
    print("QUALITY SCORE BREAKDOWN:")
    for explanation in quality_explanation:
        print(f"  {explanation}")
    
    inclusivity_score, inclusivity_explanation = calculate_inclusivity_score(
        diverse_examples=False,  # Default generation
        gender_neutral=True,     # Assumed good
        multiple_perspectives=False,
        accessible_language=True,
        global_examples=False,
        cultural_bias=False,     # Low bias score suggests this
        gender_stereotypes=False,
        socioeconomic_assumptions=False
    )
    
    print("\nINCLUSIVITY SCORE BREAKDOWN:")
    for explanation in inclusivity_explanation:
        print(f"  {explanation}")